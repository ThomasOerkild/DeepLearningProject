{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:33.974171Z",
     "start_time": "2017-11-20T20:18:30.442100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import Utils\n",
    "import os\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:35.955828Z",
     "start_time": "2017-11-20T20:18:33.975672Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.VGG16(include_top=False,weights='imagenet')\n",
    "vgg16_graph = keras.backend.get_session().graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:35.997870Z",
     "start_time": "2017-11-20T20:18:35.957831Z"
    }
   },
   "outputs": [],
   "source": [
    "w_1_1 = vgg16_graph.get_tensor_by_name('block1_conv1/kernel:0')\n",
    "b_1_1 = vgg16_graph.get_tensor_by_name('block1_conv1/bias:0')\n",
    "w_1_2 = vgg16_graph.get_tensor_by_name('block1_conv2/kernel:0')\n",
    "b_1_2 = vgg16_graph.get_tensor_by_name('block1_conv2/bias:0')\n",
    "\n",
    "w_2_1 = vgg16_graph.get_tensor_by_name('block2_conv1/kernel:0')\n",
    "b_2_1 = vgg16_graph.get_tensor_by_name('block2_conv1/bias:0')\n",
    "w_2_2 = vgg16_graph.get_tensor_by_name('block2_conv2/kernel:0')\n",
    "b_2_2 = vgg16_graph.get_tensor_by_name('block2_conv2/bias:0')\n",
    "\n",
    "w_3_1 = vgg16_graph.get_tensor_by_name('block3_conv1/kernel:0')\n",
    "b_3_1 = vgg16_graph.get_tensor_by_name('block3_conv1/bias:0')\n",
    "w_3_2 = vgg16_graph.get_tensor_by_name('block3_conv2/kernel:0')\n",
    "b_3_2 = vgg16_graph.get_tensor_by_name('block3_conv2/bias:0')\n",
    "w_3_3 = vgg16_graph.get_tensor_by_name('block3_conv3/kernel:0')\n",
    "b_3_3 = vgg16_graph.get_tensor_by_name('block3_conv3/bias:0')\n",
    "\n",
    "w_4_1 = vgg16_graph.get_tensor_by_name('block4_conv1/kernel:0')\n",
    "b_4_1 = vgg16_graph.get_tensor_by_name('block4_conv1/bias:0')\n",
    "w_4_2 = vgg16_graph.get_tensor_by_name('block4_conv2/kernel:0')\n",
    "b_4_2 = vgg16_graph.get_tensor_by_name('block4_conv2/bias:0')\n",
    "w_4_3 = vgg16_graph.get_tensor_by_name('block4_conv3/kernel:0')\n",
    "b_4_3 = vgg16_graph.get_tensor_by_name('block4_conv3/bias:0')\n",
    "\n",
    "w_5_1 = vgg16_graph.get_tensor_by_name('block5_conv1/kernel:0')\n",
    "b_5_1 = vgg16_graph.get_tensor_by_name('block5_conv1/bias:0')\n",
    "w_5_2 = vgg16_graph.get_tensor_by_name('block5_conv2/kernel:0')\n",
    "b_5_2 = vgg16_graph.get_tensor_by_name('block5_conv2/bias:0')\n",
    "w_5_3 = vgg16_graph.get_tensor_by_name('block5_conv3/kernel:0')\n",
    "b_5_3 = vgg16_graph.get_tensor_by_name('block5_conv3/bias:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:36.014885Z",
     "start_time": "2017-11-20T20:18:35.999872Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_classes = 12\n",
    "batch_size = 8\n",
    "input_shape = (batch_size, 352, 480, 3)\n",
    "label_shape = (batch_size, 352, 480, number_of_classes)\n",
    "\n",
    "images=tf.placeholder(dtype=tf.float32,shape=input_shape)\n",
    "labels_im=tf.placeholder(dtype=tf.float32,shape=label_shape)\n",
    "\n",
    "#images=tf.placeholder(dtype=tf.float32,shape=(1, 720, 960, 3))\n",
    "strides = (1,1,1,1)\n",
    "padding = 'SAME'\n",
    "max_pooling_ksize = (1,2,2,1)\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:36.049918Z",
     "start_time": "2017-11-20T20:18:36.016887Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpool_with_argmax(pool, ind, name = None, ksize=[1, 2, 2, 1]):\n",
    "\n",
    "    \"\"\"\n",
    "       Unpooling layer after max_pool_with_argmax.\n",
    "       Args:\n",
    "           pool:   max pooled output tensor\n",
    "           ind:      argmax indices\n",
    "           ksize:     ksize is the same as for the pool\n",
    "       Return:\n",
    "           unpool:    unpooling tensor\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        input_shape = pool.get_shape().as_list()\n",
    "        print(\"input_shape: {0}, ind: {1}\".format(pool.shape, ind.shape))\n",
    "        output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n",
    "\n",
    "        flat_input_size = tf.reduce_prod(input_shape)\n",
    "        flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]\n",
    "\n",
    "        pool_ = tf.reshape(pool, [flat_input_size])\n",
    "        batch_range = tf.reshape(tf.range(output_shape[0], dtype=ind.dtype), shape=[input_shape[0], 1, 1, 1])\n",
    "        b = tf.ones_like(ind) * batch_range\n",
    "        b = tf.reshape(b, [flat_input_size, 1])\n",
    "        ind_ = tf.reshape(ind, [flat_input_size, 1])\n",
    "        ind_ = tf.concat([b, ind_], 1)\n",
    "\n",
    "        ret = tf.scatter_nd(ind_, pool_, shape=flat_output_shape)\n",
    "        ret = tf.reshape(ret, output_shape)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:36.108475Z",
     "start_time": "2017-11-20T20:18:36.051920Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoding_layer(input, filter1, filter2, bias1, bias2, conv_stride, name=None, filter3=None, bias3=None, max_pool_stride = (1,2,2,1)):\n",
    "    with tf.name_scope(name):\n",
    "        conv_1= tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = input,filter=filter1, strides=conv_stride, padding=padding), bias1)))\n",
    "        conv_2= tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = conv_1,filter=filter2, strides=conv_stride, padding=padding), bias2)))\n",
    "        if filter3 != None and bias3 != None:\n",
    "            conv_3 = tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = conv_2,filter=filter3, strides=conv_stride, padding=padding), bias3)))\n",
    "            return tf.nn.max_pool_with_argmax(conv_3, ksize=max_pooling_ksize,strides=(1,2,2,1), padding='VALID')\n",
    "        else:\n",
    "            return tf.nn.max_pool_with_argmax(conv_2, ksize=max_pooling_ksize,strides=(1,2,2,1), padding='VALID')\n",
    "\n",
    "def decoding_layer(input, indicies, filter1_shape, filter2_shape, name=None, filter3_shape=None):\n",
    "    with tf.name_scope(name):\n",
    "        upsample = unpool_with_argmax(input, indicies, name=name+\"Upsample\")\n",
    "        if filter3_shape != None:\n",
    "            deconv_1 = tf.layers.batch_normalization(tf.layers.conv2d(upsample, filter3_shape,(3,3),activation=tf.nn.relu, padding='same'))\n",
    "            deconv_2 = tf.layers.batch_normalization(tf.layers.conv2d(deconv_1, filter2_shape,(3,3),activation=tf.nn.relu, padding='same'))\n",
    "            return tf.layers.batch_normalization(tf.layers.conv2d(deconv_2, filter1_shape,(3,3),activation=tf.nn.relu, padding='same'))\n",
    "        else:\n",
    "            deconv_1 = tf.layers.batch_normalization(tf.layers.conv2d(upsample, filter2_shape,(3,3),activation=tf.nn.relu, padding='same'))\n",
    "            return tf.layers.batch_normalization(tf.layers.conv2d(deconv_1, filter1_shape,(3,3),activation=tf.nn.relu, padding='same'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:39.113101Z",
     "start_time": "2017-11-20T20:18:36.110477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (2, 11, 15, 512), ind: (2, 11, 15, 512)\n",
      "input_shape: (2, 22, 30, 512), ind: (2, 22, 30, 512)\n",
      "input_shape: (2, 44, 60, 256), ind: (2, 44, 60, 256)\n",
      "input_shape: (2, 88, 120, 128), ind: (2, 88, 120, 128)\n",
      "input_shape: (2, 176, 240, 64), ind: (2, 176, 240, 64)\n",
      "correctPred: (2, 352, 480)\n"
     ]
    }
   ],
   "source": [
    "max_pooling_1, indicies_1 = encoding_layer(images, w_1_1, w_1_2, b_1_1, b_1_2, conv_stride=strides, name=\"Encoding_layer_1\")\n",
    "\n",
    "max_pooling_2, indicies_2 = encoding_layer(max_pooling_1, w_2_1, w_2_2, b_2_1, b_2_2, conv_stride=strides, name=\"Encoding_layer_2\")\n",
    "max_pooling_3, indicies_3 = encoding_layer(max_pooling_2, w_3_1, w_3_2, b_3_1, b_3_2, conv_stride=strides, name=\"Encoding_layer_3\", filter3=w_3_3, bias3=b_3_3)\n",
    "max_pooling_4, indicies_4 = encoding_layer(max_pooling_3, w_4_1, w_4_2, b_4_1, b_4_2, conv_stride=strides, name=\"Encoding_layer_4\", filter3=w_4_3, bias3=b_4_3)\n",
    "max_pooling_5, indicies_5 = encoding_layer(max_pooling_4, w_5_1, w_5_2, b_5_1, b_5_2, conv_stride=strides, name=\"Encoding_layer_5\", filter3=w_5_3, bias3=b_5_3)\n",
    "\n",
    "deconv_1 = decoding_layer(max_pooling_5, indicies_5, w_5_1.shape[2].value, w_5_2.shape[2].value, name= \"Decoding_layer_1\", filter3_shape=w_5_3.shape[2].value)\n",
    "deconv_2 = decoding_layer(deconv_1, indicies_4, w_4_1.shape[2].value, w_4_2.shape[2].value, name= \"Decoding_layer_2\", filter3_shape=w_4_3.shape[2].value)\n",
    "deconv_3 = decoding_layer(deconv_2, indicies_3, w_3_1.shape[2].value, w_3_2.shape[2].value, name= \"Decoding_layer_3\", filter3_shape=w_3_3.shape[2].value)\n",
    "deconv_4 = decoding_layer(deconv_3, indicies_2, w_2_1.shape[2].value, w_2_2.shape[2].value, name= \"Decoding_layer_4\")\n",
    "deconv_5 = decoding_layer(deconv_4, indicies_1, number_of_classes, w_1_2.shape[2].value, name= \"Decoding_layer_5\")\n",
    "\n",
    "out = tf.nn.softmax(deconv_5)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=labels_im))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(out,-1), tf.argmax(labels_im,-1))\n",
    "print(\"correctPred: {0}\".format(correctPred.shape))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "train_accu = tf.summary.scalar(\"train_accu\", accuracy)\n",
    "\n",
    "train_loss = tf.summary.scalar(\"train_loss\", loss)\n",
    "\n",
    "train_summ = tf.summary.merge((train_accu, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:43.811164Z",
     "start_time": "2017-11-20T20:18:39.115092Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(\"tensorboard_logs\")\n",
    "writer.add_graph(sess.graph)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:18:47.999334Z",
     "start_time": "2017-11-20T20:18:43.813155Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = np.asarray(Utils.load_images(\"../Data/CamVid/train/\"))\n",
    "test_images = np.asarray(Utils.load_images(\"../Data/CamVid/test/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:19:29.613172Z",
     "start_time": "2017-11-20T20:18:48.001324Z"
    }
   },
   "outputs": [],
   "source": [
    "train_annotations = np.asarray(Utils.load_annotations(\"../Data/CamVid/trainannot/\"))\n",
    "test_annotations = np.asarray(Utils.load_annotations(\"../Data/CamVid/testannot/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:19:29.681228Z",
     "start_time": "2017-11-20T20:19:29.644192Z"
    }
   },
   "outputs": [],
   "source": [
    "training_bp = Utils.BatchProcessor()\n",
    "test_bp = Utils.BatchProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T20:21:23.951871Z",
     "start_time": "2017-11-20T20:19:29.686249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/18350 Test accu: 0.25138533115386963, test loss: 2.4848742485046387\n",
      "50/18350 Test accu: 0.2549406886100769, test loss: 2.363787889480591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cc91e668d795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_bp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_annotations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_im\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(int(num_epochs*len(train_images) / batch_size)):\n",
    "    batch_X, batch_y = training_bp.get_next_batch(train_images, train_annotations, batch_size)\n",
    "    \n",
    "    sess.run(train_step,feed_dict={images: batch_X,labels_im: batch_y})\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        accus = []\n",
    "        losss = []\n",
    "        for j in range(int(len(test_images)/batch_size)):\n",
    "            test_batch_x, test_batch_y = test_bp.get_next_batch(test_images, test_annotations, batch_size)\n",
    "            loss_o, accu_o = sess.run([loss,accuracy],feed_dict={images: test_batch_x,labels_im: test_batch_y})\n",
    "            accus.append(accu_o)\n",
    "            losss.append(loss_o)\n",
    "        train_summary = sess.run(train_summ,feed_dict={images: batch_X,labels_im: batch_y})\n",
    "        writer.add_summary(train_summary, i)\n",
    "        \n",
    "        test_sum = tf.Summary()\n",
    "        test_sum.value.add(tag=\"TestAccuracy\", simple_value =np.mean(accus))\n",
    "        writer.add_summary(test_sum, i)\n",
    "        print(\"{2}/{3} Test accu: {0}, test loss: {1}\".format(np.mean(accus), np.mean(losss), i, int(num_epochs*len(train_images) / batch_size)))\n",
    "    \n",
    "    if i % 1000 == 0 and i!=0:\n",
    "        save_path = saver.save(sess, os.path.join('..','saved_models','model.ckpt'))\n",
    "        print(\"Model saved to: %s\" % save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
