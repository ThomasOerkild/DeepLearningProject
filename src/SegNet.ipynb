{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:42:29.705252Z",
     "start_time": "2017-12-16T17:42:26.065604Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import Utils\n",
    "import os\n",
    "import keras\n",
    "from time import gmtime, strftime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:42:32.302059Z",
     "start_time": "2017-12-16T17:42:30.516991Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "number_of_classes = 12\n",
    "batch_size = 2\n",
    "input_shape = (batch_size, 352, 480, 3)\n",
    "label_shape = (batch_size, 352, 480, number_of_classes)\n",
    "dropout_prob = 0.5\n",
    "strides = (1,1,1,1)\n",
    "padding = 'SAME'\n",
    "max_pooling_ksize = (1,2,2,1)\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 125\n",
    "\n",
    "baysian_segnet_path = os.path.join('..','saved_models',\"baysian_segnet_no_mfb\",\"baysian_segnet_model.ckpt\")\n",
    "segnet_path = os.path.join('..','saved_models',\"segnet_no_mfb\",\"segnet_model.ckpt\")\n",
    "\n",
    "train_data_path = os.path.join(\"..\",\"Data\", \"CamVid\",\"train\")\n",
    "test_data_path = os.path.join(\"..\",\"Data\", \"CamVid\",\"test\")\n",
    "train_anno_path = os.path.join(\"..\",\"Data\", \"CamVid\",\"trainannot\")\n",
    "test_anno_path = os.path.join(\"..\",\"Data\", \"CamVid\",\"testannot\")\n",
    "\n",
    "class SegNet:\n",
    "    \n",
    "    \n",
    "    def __init__(self, load_model=False, baysian=False, use_mfb=True):\n",
    "        self.baysian= baysian\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.build_model()\n",
    "        if load_model:\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.train_model(use_mfb=use_mfb)\n",
    "            \n",
    "    \n",
    "    def load_model(self):\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        if self.baysian:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(self.sess, baysian_segnet_path)\n",
    "        else:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(self.sess, segnet_path)\n",
    "         \n",
    "    \n",
    "    def feed_forward(self, images):\n",
    "        assert np.shape(images) == input_shape\n",
    "        return self.sess.run(self.prediction, feed_dict={self.images: images})\n",
    "        \n",
    "    \n",
    "    def predict(self, images):\n",
    "        assert np.shape(images) == input_shape\n",
    "        \n",
    "        if self.baysian:\n",
    "            predictions = []\n",
    "            for i in range(50):\n",
    "                predictions.append(self.feed_forward(images))\n",
    "            \n",
    "            return np.mean(predictions, axis=0), np.var(predictions, axis=0)\n",
    "            \n",
    "        else:\n",
    "            return self.feed_forward(images)\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.images=tf.placeholder(dtype=tf.float32,shape=input_shape)\n",
    "        self.labels_im=tf.placeholder(dtype=tf.float32,shape=label_shape)\n",
    "        \n",
    "        self.scaling_vector = tf.placeholder(dtype=tf.float32, shape=[number_of_classes])\n",
    "        \n",
    "        vgg16 = keras.applications.VGG16(include_top=False,weights='imagenet')\n",
    "        vgg16_graph = keras.backend.get_session().graph\n",
    "        w_1_1 = vgg16_graph.get_tensor_by_name('block1_conv1/kernel:0')\n",
    "        b_1_1 = vgg16_graph.get_tensor_by_name('block1_conv1/bias:0')\n",
    "        w_1_2 = vgg16_graph.get_tensor_by_name('block1_conv2/kernel:0')\n",
    "        b_1_2 = vgg16_graph.get_tensor_by_name('block1_conv2/bias:0')\n",
    "\n",
    "        w_2_1 = vgg16_graph.get_tensor_by_name('block2_conv1/kernel:0')\n",
    "        b_2_1 = vgg16_graph.get_tensor_by_name('block2_conv1/bias:0')\n",
    "        w_2_2 = vgg16_graph.get_tensor_by_name('block2_conv2/kernel:0')\n",
    "        b_2_2 = vgg16_graph.get_tensor_by_name('block2_conv2/bias:0')\n",
    "\n",
    "        w_3_1 = vgg16_graph.get_tensor_by_name('block3_conv1/kernel:0')\n",
    "        b_3_1 = vgg16_graph.get_tensor_by_name('block3_conv1/bias:0')\n",
    "        w_3_2 = vgg16_graph.get_tensor_by_name('block3_conv2/kernel:0')\n",
    "        b_3_2 = vgg16_graph.get_tensor_by_name('block3_conv2/bias:0')\n",
    "        w_3_3 = vgg16_graph.get_tensor_by_name('block3_conv3/kernel:0')\n",
    "        b_3_3 = vgg16_graph.get_tensor_by_name('block3_conv3/bias:0')\n",
    "\n",
    "        w_4_1 = vgg16_graph.get_tensor_by_name('block4_conv1/kernel:0')\n",
    "        b_4_1 = vgg16_graph.get_tensor_by_name('block4_conv1/bias:0')\n",
    "        w_4_2 = vgg16_graph.get_tensor_by_name('block4_conv2/kernel:0')\n",
    "        b_4_2 = vgg16_graph.get_tensor_by_name('block4_conv2/bias:0')\n",
    "        w_4_3 = vgg16_graph.get_tensor_by_name('block4_conv3/kernel:0')\n",
    "        b_4_3 = vgg16_graph.get_tensor_by_name('block4_conv3/bias:0')\n",
    "\n",
    "        w_5_1 = vgg16_graph.get_tensor_by_name('block5_conv1/kernel:0')\n",
    "        b_5_1 = vgg16_graph.get_tensor_by_name('block5_conv1/bias:0')\n",
    "        w_5_2 = vgg16_graph.get_tensor_by_name('block5_conv2/kernel:0')\n",
    "        b_5_2 = vgg16_graph.get_tensor_by_name('block5_conv2/bias:0')\n",
    "        w_5_3 = vgg16_graph.get_tensor_by_name('block5_conv3/kernel:0')\n",
    "        b_5_3 = vgg16_graph.get_tensor_by_name('block5_conv3/bias:0')\n",
    "        \n",
    "        max_pooling_1, indicies_1 = self.encoding_layer(self.images, w_1_1, w_1_2, b_1_1, b_1_2, conv_stride=strides, name=\"Encoding_layer_1\")\n",
    "\n",
    "        max_pooling_2, indicies_2 = self.encoding_layer(max_pooling_1, w_2_1, w_2_2, b_2_1, b_2_2, conv_stride=strides, name=\"Encoding_layer_2\")\n",
    "        max_pooling_3, indicies_3 = self.encoding_layer(max_pooling_2, w_3_1, w_3_2, b_3_1, b_3_2, conv_stride=strides, name=\"Encoding_layer_3\", filter3=w_3_3, bias3=b_3_3, dropout=self.baysian)\n",
    "        max_pooling_4, indicies_4 = self.encoding_layer(max_pooling_3, w_4_1, w_4_2, b_4_1, b_4_2, conv_stride=strides, name=\"Encoding_layer_4\", filter3=w_4_3, bias3=b_4_3, dropout=self.baysian)\n",
    "        max_pooling_5, indicies_5 = self.encoding_layer(max_pooling_4, w_5_1, w_5_2, b_5_1, b_5_2, conv_stride=strides, name=\"Encoding_layer_5\", filter3=w_5_3, bias3=b_5_3, dropout=self.baysian)\n",
    "\n",
    "        deconv_1 = self.decoding_layer(max_pooling_5, indicies_5, w_5_1.shape[2].value, w_5_2.shape[2].value, name= \"Decoding_layer_1\", filter3_shape=w_5_3.shape[2].value, dropout=self.baysian)\n",
    "        deconv_2 = self.decoding_layer(deconv_1, indicies_4, w_4_1.shape[2].value, w_4_2.shape[2].value, name= \"Decoding_layer_2\", filter3_shape=w_4_3.shape[2].value, dropout=self.baysian)\n",
    "        deconv_3 = self.decoding_layer(deconv_2, indicies_3, w_3_1.shape[2].value, w_3_2.shape[2].value, name= \"Decoding_layer_3\", filter3_shape=w_3_3.shape[2].value, dropout=self.baysian)\n",
    "        deconv_4 = self.decoding_layer(deconv_3, indicies_2, w_2_1.shape[2].value, w_2_2.shape[2].value, name= \"Decoding_layer_4\")\n",
    "        deconv_5 = self.decoding_layer(deconv_4, indicies_1, number_of_classes, w_1_2.shape[2].value, name= \"Decoding_layer_5\")\n",
    "\n",
    "        out = tf.nn.softmax(deconv_5) # (batch_size, width, height, num_classes)\n",
    "        weights = tf.multiply(self.labels_im, self.scaling_vector)\n",
    "        weights = tf.reduce_sum(weights, 3)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.labels_im, logits=deconv_5, weights=weights)\n",
    "        \n",
    "        #self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=scaled_out, labels=scaled_labels))\n",
    "        self.train_step = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "        self.prediction = tf.argmax(out,-1)\n",
    "        correctPred = tf.equal(self.prediction, tf.argmax(self.labels_im,-1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "    \n",
    "    def train_model(self, model_is_loaded=False, use_mfb=True):\n",
    "        train_accu = tf.summary.scalar(\"train_accu\", self.accuracy)\n",
    "        train_loss = tf.summary.scalar(\"train_loss\", self.loss)\n",
    "        train_summ = tf.summary.merge((train_accu, train_loss))\n",
    "        \n",
    "        if not model_is_loaded:\n",
    "            init = tf.global_variables_initializer()\n",
    "            self.sess = tf.Session()\n",
    "            self.sess.run(init)\n",
    "            \n",
    "        if self.baysian:\n",
    "            logdir = os.path.join(\"tensorboard_logs\",\"Baysian_SegNet\"+strftime(\"_%Y-%m-%d\", gmtime()))\n",
    "        else:\n",
    "            logdir = os.path.join(\"tensorboard_logs\",\"SegNet\"+strftime(\"_%Y-%m-%d\", gmtime()))\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        writer.add_graph(self.sess.graph)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        train_images = np.asarray(Utils.load_images(train_data_path))\n",
    "        test_images = np.asarray(Utils.load_images(test_data_path))\n",
    "        \n",
    "        train_annotations = np.asarray(Utils.load_annotations(train_anno_path))\n",
    "        test_annotations = np.asarray(Utils.load_annotations(test_anno_path))\n",
    "        \n",
    "        shuffler = np.arange(len(train_images))\n",
    "        np.random.shuffle(shuffler)\n",
    "        train_images = train_images[shuffler]\n",
    "        train_annotations = train_annotations[shuffler]\n",
    "        \n",
    "        training_bp = Utils.BatchProcessor()\n",
    "        test_bp = Utils.BatchProcessor()\n",
    "        \n",
    "        if use_mfb:\n",
    "            train_scaling_vector = Utils.get_class_balance_vector(train_anno_path)\n",
    "        else:\n",
    "            train_scaling_vector = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "        \n",
    "        for i in range(int(num_epochs*len(train_images) / batch_size)):\n",
    "            batch_X, batch_y = training_bp.get_next_batch(train_images, train_annotations, batch_size)\n",
    "\n",
    "            self.sess.run(self.train_step,feed_dict={self.images: batch_X,self.labels_im: batch_y, self.scaling_vector: train_scaling_vector})\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                accus = []\n",
    "                losss = []\n",
    "                for j in range(int(len(test_images)/batch_size)):\n",
    "                    test_batch_x, test_batch_y = test_bp.get_next_batch(test_images, test_annotations, batch_size)\n",
    "                    loss_o, accu_o = self.sess.run([self.loss,self.accuracy],feed_dict={self.images: test_batch_x,self.labels_im: test_batch_y, self.scaling_vector: train_scaling_vector})\n",
    "                    accus.append(accu_o)\n",
    "                    losss.append(loss_o)\n",
    "                train_summary = self.sess.run(train_summ,feed_dict={self.images: batch_X,self.labels_im: batch_y, self.scaling_vector: train_scaling_vector})\n",
    "                writer.add_summary(train_summary, i+10000)\n",
    "\n",
    "                test_sum = tf.Summary()\n",
    "                test_sum.value.add(tag=\"TestAccuracy\", simple_value =np.mean(accus))\n",
    "                writer.add_summary(test_sum, i+10000)\n",
    "                print(\"{2}/{3} Test accu: {0}, test loss: {1}\".format(np.mean(accus), np.mean(losss), i, int(num_epochs*len(train_images) / batch_size)))\n",
    "\n",
    "            if i % 1000 == 0 and i!=0:\n",
    "                if self.baysian:\n",
    "                    save_path = saver.save(self.sess, baysian_segnet_path)\n",
    "                else:\n",
    "                    save_path = saver.save(self.sess, segnet_path)\n",
    "                \n",
    "                print(\"Model saved to: %s\" % save_path)\n",
    "\n",
    "        \n",
    "    def encoding_layer(self, input, filter1, filter2, bias1, bias2, conv_stride, name=None, filter3=None, bias3=None, max_pool_stride = (1,2,2,1), dropout=False):\n",
    "        with tf.name_scope(name):\n",
    "            conv_1= tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = input,filter=filter1, strides=conv_stride, padding=padding), bias1)))\n",
    "            conv_2= tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = conv_1,filter=filter2, strides=conv_stride, padding=padding), bias2)))\n",
    "            if filter3 != None and bias3 != None:\n",
    "                conv_3 = tf.layers.batch_normalization(tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input = conv_2,filter=filter3, strides=conv_stride, padding=padding), bias3)))\n",
    "                \n",
    "                max_pool, indicies = tf.nn.max_pool_with_argmax(conv_3, ksize=max_pooling_ksize,strides=(1,2,2,1), padding='VALID')\n",
    "            else:\n",
    "                max_pool, indicies = tf.nn.max_pool_with_argmax(conv_2, ksize=max_pooling_ksize,strides=(1,2,2,1), padding='VALID')\n",
    "            \n",
    "            if dropout:\n",
    "                return tf.nn.dropout(max_pool, keep_prob=1-dropout_prob), indicies\n",
    "            else:\n",
    "                return max_pool, indicies\n",
    "\n",
    "    def decoding_layer(self, input, indicies, filter1_shape, filter2_shape, name=None, filter3_shape=None, dropout=False):\n",
    "        with tf.name_scope(name):\n",
    "            upsample = Utils.unpool_with_argmax(input, indicies, name=name+\"Upsample\")\n",
    "            if filter3_shape != None:\n",
    "                deconv_1 = tf.layers.batch_normalization(tf.layers.conv2d(upsample, filter3_shape,(3,3),activation=tf.nn.relu, padding='same', kernel_initializer=tf.contrib.layers.variance_scaling_initializer()))\n",
    "                deconv_2 = tf.layers.batch_normalization(tf.layers.conv2d(deconv_1, filter2_shape,(3,3),activation=tf.nn.relu, padding='same',kernel_initializer=tf.contrib.layers.variance_scaling_initializer()))\n",
    "                max_pool =  tf.layers.batch_normalization(tf.layers.conv2d(deconv_2, filter1_shape,(3,3),activation=tf.nn.relu, padding='same', kernel_initializer=tf.contrib.layers.variance_scaling_initializer()))\n",
    "            else:\n",
    "                deconv_1 = tf.layers.batch_normalization(tf.layers.conv2d(upsample, filter2_shape,(3,3),activation=tf.nn.relu, padding='same',kernel_initializer=tf.contrib.layers.variance_scaling_initializer()))\n",
    "                max_pool =  tf.layers.batch_normalization(tf.layers.conv2d(deconv_1, filter1_shape,(3,3),activation=tf.nn.relu, padding='same', kernel_initializer=tf.contrib.layers.variance_scaling_initializer()))\n",
    "                \n",
    "            if dropout:\n",
    "                return tf.nn.dropout(max_pool, keep_prob=1-dropout_prob)\n",
    "            else:\n",
    "                return max_pool\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:42:41.702665Z",
     "start_time": "2017-12-16T17:42:33.126302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (2, 11, 15, 512), ind: (2, 11, 15, 512)\n",
      "input_shape: (2, 22, 30, 512), ind: (2, 22, 30, 512)\n",
      "input_shape: (2, 44, 60, 256), ind: (2, 44, 60, 256)\n",
      "input_shape: (2, 88, 120, 128), ind: (2, 88, 120, 128)\n",
      "input_shape: (2, 176, 240, 64), ind: (2, 176, 240, 64)\n",
      "INFO:tensorflow:Restoring parameters from ..\\saved_models\\segnet_no_mfb\\segnet_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "segnet = SegNet(load_model=True, baysian=False, use_mfb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:42:41.756171Z",
     "start_time": "2017-12-16T17:42:41.702665Z"
    }
   },
   "outputs": [],
   "source": [
    "images, annotations = Utils.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:43:15.352659Z",
     "start_time": "2017-12-16T17:43:15.110982Z"
    }
   },
   "outputs": [],
   "source": [
    "prediciton = segnet.predict(images[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T17:43:21.723907Z",
     "start_time": "2017-12-16T17:43:21.523407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAD8CAYAAAAoqlyCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4f516e160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prediciton[1])\n",
    "plt.savefig(\"segnet_no_mfb_test_im_3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-12T07:58:59.632Z"
    }
   },
   "outputs": [],
   "source": [
    "segnet.train_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-10T20:00:57.616186Z",
     "start_time": "2017-12-10T20:00:57.602665Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(prediciton[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T19:20:05.301487Z",
     "start_time": "2017-12-13T19:20:05.157337Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(prediciton[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T19:20:32.434473Z",
     "start_time": "2017-12-13T19:20:15.072787Z"
    }
   },
   "outputs": [],
   "source": [
    "annos = np.argmax(Utils.load_annotations(test_anno_path), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-10T13:41:15.132145Z",
     "start_time": "2017-12-10T13:41:14.923612Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(annos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-09T15:24:23.936001Z",
     "start_time": "2017-12-09T13:00:04.794420Z"
    }
   },
   "outputs": [],
   "source": [
    "segnet = SegNet(load_model=False, baysian=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
